[GROQ CONFIG]
BASEURL = https://api.groq.com/openai/v1

[DETAIL EXTRACTOR]
VLM = meta-llama/llama-4-maverick-17b-128e-instruct
BATCHSIZE = 5
MAXTOKENS = 1024
TEMPERATURE = 0.5

[SUMMARIZER]
LLM = meta-llama/llama-4-maverick-17b-128e-instruct
MAXTOKENS = 2048
TEMPERATURE = 0.5